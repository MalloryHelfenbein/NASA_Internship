{"cells":[{"cell_type":"markdown","id":"39701b02","metadata":{"id":"39701b02"},"source":["## ADS Searcher Notebook\n","\n","This notebook includes all of the necessary functions to take a list of names or institutions and find the expertise of that author or the authors in that institution based on publications in ADS.\n","\n","Before the code begins here are the things needed:\n","1. The supporting file **TextAnalysis.py**.\n","2. A file of ignorable \"stop words\" and its directory path: **stopwords.txt**.\n","3. Your own **NASA ADS API token**. This is a long string of characters generated by ADS that gives you acces to their API\n","4. Either an input author/institution or an input csv file that has all authors/institutions you want to run.\n","\n","Set up of this notebook:\n","- The steps of the process are listed out in each individual function (make sure to run these cells)\n","- At the end is the final for loop that you will input the csv file. This function contains multiple different pathways based on the input you give it.\n"]},{"cell_type":"markdown","id":"cd8a9f09","metadata":{"id":"cd8a9f09"},"source":["### Step 1: Import statements and getting all necessary files"]},{"cell_type":"code","execution_count":null,"id":"f86814e6","metadata":{"id":"f86814e6"},"outputs":[],"source":["import requests\n","from urllib.parse import urlencode, quote_plus\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"2dcdab4e","metadata":{"id":"2dcdab4e"},"outputs":[],"source":["import pandas as pd\n","print(pd. __version__)"]},{"cell_type":"code","execution_count":null,"id":"4367e68e","metadata":{"id":"4367e68e"},"outputs":[],"source":["token = 'Z6VGw27uH9j2oYKa3t8zqdSmOMK8G5zEGbVnAdsD ' #edit this for yourself"]},{"cell_type":"code","execution_count":null,"id":"2d0b2f88","metadata":{"id":"2d0b2f88"},"outputs":[],"source":["directory= 'C:\\\\Users\\\\mhelfenb\\\\NASA_internship\\stopwords.txt' #edit this directory path for yourself\n","import sys\n","sys.path.append('C:\\\\Users\\\\mhelfenb\\\\NASA_internship') #edit this\n","import TextAnalysis as TA"]},{"cell_type":"markdown","id":"63a7485d","metadata":{"id":"63a7485d"},"source":["### Step 2: ADS Search function (retrieving the ADS info)\n","#### Inputs: name (optional), institution (optional), year (optional), and refereed property (optional) - choose the input\n","#### Outputs: Title, First author, bibcode, abstract, affiliation, publication date and keywords of each publication by this specific author"]},{"cell_type":"code","execution_count":null,"id":"9cc3f0e7","metadata":{"id":"9cc3f0e7"},"outputs":[],"source":["def ads_search(name=None, institution=None, year= None, refereed= 'property:notrefereed OR property:refereed'):\n","\n","#editing query input here\n","\n","    if name:\n","        if institution:\n","            query = 'pos(institution:\"{}\",1), author:\"^{}\"'.format(institution, name)\n","            print(query)\n","        else:\n","            query = 'author:\"^{}\"'.format(name)\n","            print(query)\n","\n","    else:\n","        query = 'pos(institution:\"{}\",1)'.format(institution)\n","        print(query)\n","\n","    if year_range:\n","        if year_range=='general':\n","            startd= str(2000)\n","            endd= str(2023)\n","            years= '['+startd+' TO '+endd+']'\n","            query += ', pubdate:{}'.format(years)\n","            print(query)\n","\n","        else:\n","            startd=str(int(year)-1)\n","            endd=str(int(year)+4)\n","            years='['+startd+' TO '+endd+']'\n","            query += ', pubdate:{}'.format(years) #input year in function\n","            print(query)\n","\n","\n","#making and sending query to ADS\n","\n","    encoded_query = urlencode({\n","        \"q\": query,\n","        \"fl\": \"title, first_author, bibcode, abstract, aff, pubdate, keyword\",\n","        \"fq\": \"database:astronomy,\"+str(refereed),\n","        \"rows\": 300,\n","        \"sort\": \"date desc\"\n","    })\n","    results = requests.get(\n","        \"https://api.adsabs.harvard.edu/v1/search/query?{}\".format(encoded_query),\n","        headers={'Authorization': 'Bearer ' + token}\n","    )\n","\n","    data = results.json()[\"response\"][\"docs\"]\n","\n","#extract results into each separate detail\n","\n","    pdates = [d['pubdate'] for d in data]\n","    affiliations = [d['aff'][0] for d in data]\n","    bibcodes = [d['bibcode'] for d in data]\n","    f_auth = [d['first_author'] for d in data]\n","    keysw = [d.get('keyword', []) for d in data]\n","    titles = [d.get('title', '') for d in data]\n","    abstracts = [d.get('abstract', '') for d in data]\n","\n","#define data frame\n","\n","    df = pd.DataFrame({\n","        'Input Author': [name] * len(data),\n","        'Input Institution': [institution] * len(data),\n","        'First Author': f_auth,\n","        'Bibcode': bibcodes,\n","        'Title': titles,\n","        'Publication Date': pdates,\n","        'Keywords': keysw,\n","        'Affiliations': affiliations,\n","        'Abstract': abstracts,\n","        'Data Type': [[]]*len(data)\n","    })\n","\n","    if name==None:\n","        df['Input Author']= f_auth\n","\n","\n","    return df"]},{"cell_type":"markdown","id":"5d0b16c3","metadata":{"id":"5d0b16c3"},"source":["### Step 2.5: ADS Search (with aff instead of institution)\n","This mid step was created in case the institution is not returning any results. Due to an ADS issue, sometimes affiliation works better than institution in the query"]},{"cell_type":"code","execution_count":null,"id":"551db0a2","metadata":{"id":"551db0a2"},"outputs":[],"source":["def ads_search_aff(name=None, institution=None, year= None, refereed= 'property:notrefereed OR property:refereed'):\n","\n","#editing query input here\n","    if name:\n","\n","        if institution:\n","            query = 'pos(aff:\"{}\",1), author:\"^{}\"'.format(institution, name)\n","            print(query)\n","        else:\n","            query = 'author:\"^{}\"'.format(name)\n","            print(query)\n","\n","    else:\n","        query = 'pos(aff:\"{}\",1)'.format(institution)\n","        print(query)\n","\n","    if year_range:\n","        if year_range=='general':\n","            startd= str(2000)\n","            endd= str(2023)\n","            years= '['+startd+' TO '+endd+']'\n","            query += ', pubdate:{}'.format(years)\n","            print(query)\n","\n","        else:\n","            startd=str(int(year)-1)\n","            endd=str(int(year)+4)\n","            years='['+startd+' TO '+endd+']'\n","            query += ', pubdate:{}'.format(years) #input year in function\n","            print(query)\n","\n","\n","#making and sending query to ADS\n","\n","    encoded_query = urlencode({\n","        \"q\": query,\n","        \"fl\": \"title, first_author, bibcode, abstract, aff, pubdate, keyword\",\n","        \"fq\": \"database:astronomy,\"+str(refereed),\n","        \"rows\": 300,\n","        \"sort\": \"date desc\"\n","    })\n","    results = requests.get(\n","        \"https://api.adsabs.harvard.edu/v1/search/query?{}\".format(encoded_query),\n","        headers={'Authorization': 'Bearer ' + token}\n","    )\n","\n","    data = results.json()[\"response\"][\"docs\"]\n","\n","#extract results into each separate detail\n","\n","    pdates = [d['pubdate'] for d in data]\n","    affiliations = [d['aff'][0] for d in data]\n","    bibcodes = [d['bibcode'] for d in data]\n","    f_auth = [d['first_author'] for d in data]\n","    keysw = [d.get('keyword', []) for d in data]\n","    titles = [d.get('title', '') for d in data]\n","    abstracts = [d.get('abstract', '') for d in data]\n","\n","#define data frame\n","\n","    df = pd.DataFrame({\n","        'Input Author': [name] * len(data),\n","        'Input Institution': [institution] * len(data),\n","        'First Author': f_auth,\n","        'Bibcode': bibcodes,\n","        'Title': titles,\n","        'Publication Date': pdates,\n","        'Keywords': keysw,\n","        'Affiliations': affiliations,\n","        'Abstract': abstracts,\n","        'Data Type': [[]]*len(data)\n","    })\n","\n","    if name==None:\n","        df['Input Author']= f_auth\n","\n","\n","    return df"]},{"cell_type":"markdown","id":"13439516","metadata":{"id":"13439516"},"source":["### Step 3: Defining data type (dirty vs clean)\n","This here will label the data as \"clean\" vs \"dirty\" based on if it is published in one of the chosen journals, if the listed first author matches the input author and if the listed affiliations includes the input institution\n","\n","The input is the dataframe from step 2/2.5"]},{"cell_type":"code","execution_count":null,"id":"83a6939d","metadata":{"id":"83a6939d"},"outputs":[],"source":["def data_type(df):\n","\n","    journals = ['ApJ', 'MNRAS', 'AJ', 'Nature', 'Science', 'PASP', 'AAS', 'arXiv', 'SPIE', 'A&A']\n","\n","    for index, row in df.iterrows():\n","\n","        flag= 0\n","\n","# Journal check\n","        if any(journal in row['Bibcode'] for journal in journals):\n","            data_type_label = 'Clean'\n","        else:\n","            flag= flag+1\n","\n","#Author check\n","        if row['First Author'].lower() == row['Input Author'].lower():\n","            data_type_label = 'Clean'\n","        else:\n","            flag=flag+2\n","\n","# Inst check\n","        if institution and institution in row['Affiliations']:\n","            data_type_label = 'Clean'\n","        elif not institution:\n","            data_type_label = 'Clean'\n","        else:\n","            flag=flag+4\n","\n","# Update the 'Data Type' column\n","        if flag==0:\n","            data_type_label = 'Clean'\n","        else:\n","            data_type_label = 'Dirty'\n","\n","        df.at[index, 'Data Type'] = data_type_label\n","\n","    print(flag) #this lets the user know what aspect of the data made it 'dirty'\n","\n","#flag= 1 just the journal did, flag= 2 just the author, flag=3 the author and journal,\n","#flag=4 just the inst, etc.\n","\n","    return df\n","\n","\n"]},{"cell_type":"markdown","id":"e0062ed5","metadata":{"id":"e0062ed5"},"source":["### Step 4: Merge the publications for individual authors into one row\n","Before this step the dataframe will have each publication by each author in separate rows, here we want to combine the publications by author, i.e if an author publishes 5 times then all 5 publications are in one row with that author.\n","\n","Input here is the dataframe made in Step 3"]},{"cell_type":"code","execution_count":null,"id":"dac43f32","metadata":{"id":"dac43f32"},"outputs":[],"source":["def merge(df):\n","\n","    df['Publication Date']= df['Publication Date'].astype(str)\n","    df['Abstract']= df['Abstract'].astype(str)\n","    df['Keywords'] = df['Keywords'].apply(lambda keywords: ', '.join(keywords) if keywords else '')\n","    df['Title'] = df['Title'].apply(lambda titles: ', '.join(titles) if titles else '')\n","\n","# if the dataframe is missing any information it is labeled as \"None\"\n","\n","    df.fillna('None', inplace=True)\n","\n","    merged= df.groupby('Input Author').aggregate({'Input Institution':', '.join, 'First Author':', '.join, 'Bibcode':', '.join,\n","                                                 'Title':', '.join,'Publication Date':', '.join, 'Keywords':', '.join,\n","                                                 'Affiliations':', '.join,'Abstract':', '.join, 'Data Type':', '.join}).reset_index()\n","\n","    return merged\n","\n",""]},{"cell_type":"markdown","id":"c90ecb15","metadata":{"id":"c90ecb15"},"source":["### Step 5: Defining the n_grams for each publication  \n","This final step is to define the N_grams for each paper, meaning the top words, bigrams and trigrams found (using the TextAnalysis file)"]},{"cell_type":"code","execution_count":null,"id":"265f221b","metadata":{"id":"265f221b"},"outputs":[],"source":["def n_grams(df, directorypath): #directory path should lead to TextAnalysis.py\n","    top10Dict = {'Top 10 Words':[],\n","                 'Top 10 Bigrams':[],\n","                 'Top 10 Trigrams':[]}\n","\n","    for i in df.values:\n","        abstracts = i[8]\n","\n","        top10words = TA.topwords(abstracts, directorypath)\n","        top10bigrams = TA.topbigrams(abstracts, directorypath)\n","        top10trigrams = TA.toptrigrams(abstracts, directorypath)\n","\n","        top10Dict['Top 10 Words'].append(top10words)\n","        top10Dict['Top 10 Bigrams'].append(top10bigrams)\n","        top10Dict['Top 10 Trigrams'].append(top10trigrams)\n","\n","    top10Df = df\n","    top10Df['Top 10 Words'] = top10Dict['Top 10 Words']\n","    top10Df['Top 10 Bigrams'] = top10Dict['Top 10 Bigrams']\n","    top10Df['Top 10 Trigrams'] = top10Dict['Top 10 Trigrams']\n","\n","    top10Df = top10Df[['Input Author', 'Input Institution', 'First Author', 'Bibcode', 'Title', 'Publication Date',\n","             'Keywords', 'Affiliations', 'Abstract', 'Top 10 Words', 'Top 10 Bigrams', 'Top 10 Trigrams', 'Data Type']]\n","\n","    return top10Df"]},{"cell_type":"markdown","id":"31ba3267","metadata":{"id":"31ba3267"},"source":["### Step 6: Putting it all together\n","This function (final) takes in one file that has all of the authors or institutions you want to test and completes each step on each author or individual institution.\n","\n","**Important to note** you need to edit the 'final' function statement below based on what your personal file contains- see below in comments the details of what you may need to replace\n","\n","- If the desire is to test one singular author or one singular institution look ahead to Step 7"]},{"cell_type":"code","execution_count":null,"id":"447f52b2","metadata":{"scrolled":true,"id":"447f52b2"},"outputs":[],"source":["def final(file):\n","    dataframe= pd.read_csv(file)\n","\n","    #replace inside the brackets below with the arguments you want to use\n","    institutions= dataframe['Institution Name']\n","    names= dataframe['Author'] #format must be Last, First\n","    start_years= dataframe['Fellowship Year']\n","    referee= 'property:notrefereed OR property:refereed'\n","\n","    final_df= pd.DataFrame()\n","    count= 0\n","\n","    #starting for loop to go through the input csv file\n","    for i in np.arange(len(dataframe)):\n","\n","        #edit for what your argument will be in step 2- comment out the aspects of the dataframe that will not be included in the function\n","        inst= institutions[i]\n","        name= names[i]\n","        year= start_years[i]\n","\n","        #inputting into step 2\n","        data1= ads_search(name= name, institution= inst, year=year, refereed=referee)\n","\n","        #if the dataframe is empty and there is an author inputted into the function\n","        if name and data1.empty:\n","\n","            #if the year is an inputted argument then drop the institutution from the search\n","            if year:\n","                data1= ads_search(name=name, year=year, refereed=referee)\n","\n","                #if the dataframe is still empty for just the name and year then search for a larger year range (2000 to 2023)\n","                if data1.empty:\n","                      data1= ads_search(name=name, year='general', refereed=referee)\n","\n","            #no year input then just search  name without institution\n","            else:\n","                data1= ads_search(name, refereed=referee)\n","\n","        #if there is no name input\n","        if name==None and data1.empty:\n","            if year:\n","                data1= ads_search_aff(institution= inst, year=year, refereed=referee)\n","            else:\n","                data1= ads_search_aff(institution= inst, refereed=referee)\n","\n","        data1['Input Institution']=inst\n","\n","        data2= data_type(data1)\n","        data3= merge(data2)\n","        data4= n_grams(data3, directory)\n","\n","        final_df= final_df.append(data4, ignore_index= True)\n","        count+=1\n","        print(str(count)+' iterations done')\n","\n","    return final_df"]},{"cell_type":"markdown","id":"fcda615a","metadata":{"id":"fcda615a"},"source":["### Step 7: Entering in your own data\n","- The first cell is running through a dataframe that consists of multiple authors or institutions (in the function final)\n","- The second cell below the function 'final' is if you would just like to run through one author name or one institution name"]},{"cell_type":"markdown","id":"0b66649f","metadata":{"id":"0b66649f"},"source":["##### 7.1 USE FINAL if you are using a csv file that has specific data in it\n","- whether you want to find the expertise of specific authors, authors from a specific institution or other info you can edit the cell below to match the input you give"]},{"cell_type":"code","execution_count":null,"id":"eedc1bd5","metadata":{"id":"eedc1bd5"},"outputs":[],"source":["file= 'filename.csv'\n","complete_df= final(file)\n","complete_df.to_csv('dataframe.csv', index=False)"]},{"cell_type":"markdown","id":"aaa47fda","metadata":{"id":"aaa47fda"},"source":["##### 7.2 Use this cell if the input is only one author or institution input\n","Edit the definition statements below to match your desired input!"]},{"cell_type":"code","execution_count":null,"id":"8ef181d0","metadata":{"id":"8ef181d0"},"outputs":[],"source":["author= 'Last, First'\n","inst= 'Input Inst Here'\n","year= 2000\n","referee= 'property:notrefereed OR property:refereed'\n","d1= ads_search(name=author, inst=inst, year=year, refereed=referee)\n","d2= data_type(d1)\n","d3=merge(d2)\n","d4=n_grams(d3, directory)\n","d4"]},{"cell_type":"code","execution_count":null,"id":"4da87e09","metadata":{"id":"4da87e09"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}